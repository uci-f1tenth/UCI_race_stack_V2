defaults:
  logdir: "log/log_dir"
  traindir: "log/train_dir"
  evaldir: "log/eval_dir"
  offline_traindir: null # "log/offline/train_dir"
  offline_evaldir: null # "log/offline/eval_dir"
  seed: 0
  deterministic_run: False
  steps: 1000000
  parallel: False
  eval_every: 1000
  eval_episode_num: 10
  log_every: 1000.0
  reset_every: 0
  device: "cpu:0"
  compile: False
  precision: 32
  debug: True
  video_pred_log: True
  # Environment
  track: "austria"
  task: "max_progress"
  size: [64, 64]
  envs: 1
  action_repeat: 4
  time_limit: 1000
  grayscale: False
  prefill_agent: "gap_follower"
  prefill: 2500
  reward_EMA: True
  # Model
  dyn_hidden: 512
  dyn_deter: 512
  dyn_stoch: 32
  dyn_discrete: 32
  dyn_rec_depth: 1
  dyn_mean_act: "none"
  dyn_std_act: "sigmoid2"
  dyn_min_std: 0.1
  grad_heads: ["decoder", "reward", "cont"]
  units: 512
  act: "SiLU"
  norm: true
  encoder: {mlp_keys: "lidar", cnn_keys: "$^", act: "SiLU", norm: True, mlp_layers: 6, mlp_units: 1024, symlog_inputs: True, cnn_depth: 32, kernel_size: 4, minres: 4}
  decoder: {mlp_keys: "lidar", cnn_keys: "$^", act: "SiLU", norm: True, cnn_depth: 32, kernel_size: 4, minres: 4, mlp_layers: 4, mlp_units: 512, cnn_sigmoid: True, image_dist: "mse", vector_dist: "normal", outscale: 1.0}
  actor: {layers: 2, dist: normal, entropy: 3e-4, unimix_ratio: 0.01, std: learned, min_std: 0.1, max_std: 1.0, temp: 0.1, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 1.0}
  critic: {layers: 2, dist: symlog_disc, slow_target: true, slow_target_update: 1, slow_target_fraction: 0.02, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 0.0}
  reward_head: {layers: 2, dist: symlog_disc, loss_scale: 1.0, outscale: 0.0}
  cont_head: {layers: 2, loss_scale: 1.0, outscale: 1.0}
  dyn_scale: 0.5
  rep_scale: 0.1
  kl_free: 1.0
  weight_decay: 0.0
  unimix_ratio: 0.01
  initial: "learned"
  # Training
  batch_size: 50
  batch_length: 50
  train_ratio: 512
  pretrain: 100
  model_lr: 0.0006
  opt_eps: 1e-8
  grad_clip: 1.0
  dataset_size: 1000000
  opt: "adam"
  time_limit_train: 2000
  time_limit_test: 4000
  # Behavior
  discount: 0.99
  discount_lambda: 0.95
  imag_horizon: 15
  imag_gradient: "dynamics"
  imag_gradient_mix: 0.0
  eval_state_mean: False
  # Exploration
  expl_behavior: "greedy"
  expl_until: 0
  expl_extr_scale: 0.0
  expl_intr_scale: 1.0
  disag_target: "stoch"
  disag_log: True
  disag_models: 10
  disag_offset: 1
  disag_layers: 4
  disag_units: 400
  disag_action_cond: False
